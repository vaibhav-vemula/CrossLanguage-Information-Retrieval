{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVELOPMENT_DOCS = 'dataset/devel.docs'\n",
    "DEVELOPMENT_QUERIES = 'dataset/devel.queries'\n",
    "DEVELOPMENT_QREL = 'dataset/devel.qrel'\n",
    "BITEXT_ENG = 'dataset/bitext.en'\n",
    "BITEXT_DE = 'dataset/bitext.de'\n",
    "NEWSTEST_ENG = 'dataset/newstest.en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stemmer = nltk.stem.PorterStemmer() \n",
    "\n",
    "def tokenize(line, tokenizer=word_tokenize):\n",
    "    utf_line = line.lower()\n",
    "    return [token for token in tokenizer(utf_line)]\n",
    "\n",
    "def extract_and_tokenize_terms(doc):\n",
    "    terms = []\n",
    "    for token in tokenize(doc):\n",
    "        if token not in stopwords:\n",
    "            if not re.search(r'\\d',token) and not re.search(r'[^A-Za-z-]',token): \n",
    "                terms.append(stemmer.stem(token.lower()))\n",
    "    return terms\n",
    "\n",
    "documents = {}\n",
    "f = open(DEVELOPMENT_DOCS)\n",
    "for line in f:\n",
    "    doc = line.split(\"\\t\")\n",
    "    terms = extract_and_tokenize_terms(doc[1])\n",
    "    documents[doc[0]] = terms\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = defaultdict(set)\n",
    "\n",
    "for docid, terms in documents.items():\n",
    "    for term in terms:\n",
    "        inverted_index[term].add(docid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_DOCS = len(documents)\n",
    "AVG_LEN_DOC = sum([len(doc) for doc in documents.values()])/len(documents)\n",
    "\n",
    "def tf_idf_score(k1,b,term,docid):  \n",
    "    ft = len(inverted_index[term]) \n",
    "    term = stemmer.stem(term.lower())\n",
    "    fdt =  documents[docid].count(term)\n",
    "    idf_comp = math.log((NO_DOCS - ft + 0.5)/(ft+0.5))\n",
    "    tf_comp = ((k1 + 1)*fdt)/(k1*((1-b) + b*(len(documents[docid])/AVG_LEN_DOC))+fdt)\n",
    "    return idf_comp * tf_comp\n",
    "\n",
    "def create_tf_idf(k1,b):\n",
    "    tf_idf = defaultdict(dict)\n",
    "    for term in set(inverted_index.keys()):\n",
    "        for docid in inverted_index[term]:\n",
    "            tf_idf[term][docid] = tf_idf_score(k1,b,term,docid)\n",
    "    return tf_idf\n",
    "\n",
    "tf_idf = create_tf_idf(1.5,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('197203', 9.582576604808242),\n",
       " ('305807', 9.386382888517126),\n",
       " ('3354', 9.355859503705103),\n",
       " ('315275', 9.262398784650085),\n",
       " ('237254', 9.170402811746479)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_qtf_comp(k3,term,fqt):\n",
    "    return ((k3+1)*fqt[term])/(k3 + fqt[term])\n",
    "\n",
    "def retr_docs(query,result_count):\n",
    "    q_terms = [stemmer.stem(term.lower()) for term in query.split() if term not in stopwords]\n",
    "    fqt = {}\n",
    "    for term in q_terms:\n",
    "        fqt[term] = fqt.get(term,0) + 1\n",
    "    scores = {}\n",
    "    for word in fqt.keys():\n",
    "        for document in inverted_index[word]:\n",
    "            scores[document] = scores.get(document,0) + (tf_idf[word][document]*get_qtf_comp(0,word,fqt))\n",
    "    return sorted(scores.items(),key = lambda x : x[1] , reverse=True)[:result_count]  \n",
    "\n",
    "retr_docs(\"Berlin\",5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(BITEXT_ENG)\n",
    "train_sentences = []\n",
    "for line in f:\n",
    "    train_sentences.append(tokenize(line))\n",
    "f.close()    \n",
    "\n",
    "def check_for_unk_train(word,unigram_counts):\n",
    "    if word in unigram_counts:\n",
    "        return word\n",
    "    else:\n",
    "        unigram_counts[word] = 0\n",
    "        return \"UNK\"\n",
    "\n",
    "def convert_sentence_train(sentence,unigram_counts):\n",
    "    return [\"<s1>\"] + [\"<s2>\"] + [check_for_unk_train(token.lower(),unigram_counts) for token in sentence] + [\"</s2>\"]+ [\"</s1>\"]\n",
    "\n",
    "def get_counts(sentences):\n",
    "    unigram_counts = {}\n",
    "    for sentence in sentences:\n",
    "        sentence = convert_sentence_train(sentence, unigram_counts)\n",
    "        for i in range(len(sentence) - 2):\n",
    "            unigram_counts[sentence[i]] = unigram_counts.get(sentence[i],0) + 1\n",
    "    unigram_counts[\"</s1>\"] = unigram_counts[\"<s1>\"]\n",
    "    unigram_counts[\"</s2>\"] = unigram_counts[\"<s2>\"]\n",
    "    return unigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_counts = get_counts(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'$': 170,\n",
       " '10,000': 9,\n",
       " 'gold': 23,\n",
       " '?': 1390,\n",
       " '<s1>': 21750,\n",
       " '<s2>': 21750,\n",
       " 'UNK': 20865,\n",
       " 'san': 15,\n",
       " 'francisco': 8,\n",
       " '–': 1105,\n",
       " 'it': 2385,\n",
       " 'has': 1488,\n",
       " 'never': 138,\n",
       " 'been': 673,\n",
       " 'easy': 72,\n",
       " 'to': 6281,\n",
       " 'have': 1351,\n",
       " 'a': 5782,\n",
       " 'rational': 7,\n",
       " 'conversation': 4,\n",
       " 'about': 473,\n",
       " 'the': 18147,\n",
       " 'value': 46,\n",
       " 'of': 8389,\n",
       " '.': 18225,\n",
       " 'wouldn': 7,\n",
       " '’': 3098,\n",
       " 't': 220,\n",
       " 'you': 297,\n",
       " 'know': 104,\n",
       " 'but': 2134,\n",
       " 'january': 27,\n",
       " '1980': 59,\n",
       " 'was': 1531,\n",
       " 'arguably': 6,\n",
       " '“': 993,\n",
       " 'freak': 0,\n",
       " 'peak': 8,\n",
       " '”': 1013,\n",
       " 'during': 123,\n",
       " 'period': 43,\n",
       " 'heightened': 3,\n",
       " 'geo-political': 2,\n",
       " 'instability': 17,\n",
       " 'one': 811,\n",
       " 'answer': 55,\n",
       " ',': 15137,\n",
       " 'course': 200,\n",
       " 'is': 5466,\n",
       " 'complete': 17,\n",
       " 'collapse': 33,\n",
       " 'us': 831,\n",
       " 'dollar': 77,\n",
       " 'yes': 29,\n",
       " 'had': 370,\n",
       " 'great': 167,\n",
       " 'run': 50,\n",
       " 'so': 667,\n",
       " 'too': 290,\n",
       " 'did': 241,\n",
       " 'worldwide': 32,\n",
       " 'housing': 16,\n",
       " 'prices': 77,\n",
       " 'until': 94,\n",
       " 'couple': 9,\n",
       " 'years': 422,\n",
       " 'ago': 143,\n",
       " 'instead': 58,\n",
       " 'european': 356,\n",
       " 'union': 187,\n",
       " 'needs': 108,\n",
       " 'new': 707,\n",
       " 'direction': 30,\n",
       " 'precedents': 3,\n",
       " 'exist': 28,\n",
       " 'for': 2471,\n",
       " 'this': 1879,\n",
       " 'nato': 76,\n",
       " 'flexible': 5,\n",
       " 'since': 259,\n",
       " 'its': 866,\n",
       " 'inception': 2,\n",
       " 'countries': 550,\n",
       " 'that': 3058,\n",
       " 'want': 121,\n",
       " 'integrate': 7,\n",
       " 'further': 57,\n",
       " 'can': 886,\n",
       " 'do': 508,\n",
       " 'i': 454,\n",
       " 'am': 43,\n",
       " 'not': 2334,\n",
       " 'talking': 6,\n",
       " 'two‑speed': 0,\n",
       " 'europe': 649,\n",
       " 'influence': 47,\n",
       " 'an': 989,\n",
       " 'end': 199,\n",
       " 'in': 6782,\n",
       " 'itself': 125,\n",
       " '-': 100,\n",
       " 'means': 119,\n",
       " 'need': 217,\n",
       " 'immediate': 20,\n",
       " 'action': 59,\n",
       " 'clear': 104,\n",
       " 'eurozone': 73,\n",
       " 's': 2677,\n",
       " 'economy': 239,\n",
       " 'contracted': 2,\n",
       " 'last': 226,\n",
       " 'three': 192,\n",
       " 'months': 55,\n",
       " '2011': 39,\n",
       " ';': 400,\n",
       " 'even': 435,\n",
       " 'germany': 182,\n",
       " 'shrank': 4,\n",
       " 'france': 188,\n",
       " 'flat-lining': 0,\n",
       " '(': 486,\n",
       " 'as': 1736,\n",
       " 'britain': 74,\n",
       " ')': 488,\n",
       " 'they': 992,\n",
       " 'should': 506,\n",
       " 'maintain': 19,\n",
       " 'investment': 74,\n",
       " 'skills': 9,\n",
       " 'and': 5720,\n",
       " 'infrastructure': 35,\n",
       " 'while': 169,\n",
       " 'cutting': 5,\n",
       " 'subsidies': 9,\n",
       " 'transfer': 15,\n",
       " 'payments': 7,\n",
       " 'indeed': 289,\n",
       " 'such': 448,\n",
       " 'hopes': 12,\n",
       " 'were': 590,\n",
       " 'misplaced': 3,\n",
       " 'these': 545,\n",
       " 'analyses': 0,\n",
       " 'are': 2151,\n",
       " 'hardly': 38,\n",
       " 'neutral': 11,\n",
       " 'unwittingly': 1,\n",
       " 'enter': 11,\n",
       " 'ongoing': 12,\n",
       " 'confrontation': 5,\n",
       " 'also': 513,\n",
       " 'be': 1997,\n",
       " 'equated': 1,\n",
       " 'with': 1447,\n",
       " 'political': 361,\n",
       " 'islamism': 3,\n",
       " 'strives': 0,\n",
       " 'capitalize': 1,\n",
       " 'on': 1471,\n",
       " 'cultural': 58,\n",
       " 'debate': 62,\n",
       " 'limited': 33,\n",
       " 'arab': 96,\n",
       " 'scene': 8,\n",
       " 'when': 408,\n",
       " 'egon': 0,\n",
       " 'bahr': 0,\n",
       " 'formulated': 2,\n",
       " 'his': 495,\n",
       " 'ostpolitik': 0,\n",
       " '1960': 45,\n",
       " 'no': 695,\n",
       " 'asked': 31,\n",
       " 'will': 1197,\n",
       " 'brandt': 1,\n",
       " 'whether': 76,\n",
       " 'lost': 87,\n",
       " 'god': 28,\n",
       " 'bestowed': 2,\n",
       " 'upon': 25,\n",
       " 'turkey': 104,\n",
       " 'geographical': 3,\n",
       " 'position': 39,\n",
       " 'fundamentally': 5,\n",
       " 'requires': 43,\n",
       " 'engage': 7,\n",
       " 'east': 177,\n",
       " 'west': 153,\n",
       " 'north': 108,\n",
       " 'south': 155,\n",
       " 'symbol': 9,\n",
       " 'byzantine': 3,\n",
       " 'selçuk': 0,\n",
       " 'empires': 5,\n",
       " 'which': 445,\n",
       " 'occupied': 8,\n",
       " 'roughly': 59,\n",
       " 'same': 248,\n",
       " 'geography': 10,\n",
       " 'does': 281,\n",
       " 'today': 327,\n",
       " 'double-headed': 0,\n",
       " 'eagle': 1,\n",
       " 'looking': 20,\n",
       " 'both': 226,\n",
       " 'roman': 18,\n",
       " 'mythology': 1,\n",
       " 'janus': 0,\n",
       " 'gates': 9,\n",
       " 'doorways': 0,\n",
       " 'beginnings': 2,\n",
       " 'endings': 2,\n",
       " 'theoretical': 8,\n",
       " 'studies': 15,\n",
       " 'suggest': 15,\n",
       " 'inflation': 64,\n",
       " 'accession': 7,\n",
       " 'remain': 90,\n",
       " 'stubbornly': 0,\n",
       " 'higher': 82,\n",
       " 'than': 780,\n",
       " 'maastricht': 9,\n",
       " 'treaty': 58,\n",
       " 'allows': 9,\n",
       " '1929': 13,\n",
       " 'or': 847,\n",
       " '1989': 34,\n",
       " 'senses': 2,\n",
       " 'something': 102,\n",
       " 'like': 367,\n",
       " 'making': 73,\n",
       " 'american-asian': 0,\n",
       " 'dominated': 15,\n",
       " 'universe': 16,\n",
       " ':': 469,\n",
       " 'my': 169,\n",
       " 'space': 48,\n",
       " 'odyssey': 0,\n",
       " 'few': 107,\n",
       " 'however': 163,\n",
       " 'started': 34,\n",
       " 'paying': 10,\n",
       " 'attention': 36,\n",
       " 'again': 126,\n",
       " 'meanwhile': 26,\n",
       " '2005': 43,\n",
       " 'africa': 162,\n",
       " 'small': 135,\n",
       " 'group': 89,\n",
       " 'advising': 1,\n",
       " 'former': 78,\n",
       " 'president': 217,\n",
       " 'thabo': 3,\n",
       " 'mbeki': 4,\n",
       " 'government': 362,\n",
       " 'policy': 213,\n",
       " 'once': 125,\n",
       " 'dark': 13,\n",
       " 'screen': 4,\n",
       " 'set': 93,\n",
       " 'up': 270,\n",
       " 'mark': 15,\n",
       " 'showed': 16,\n",
       " 'home': 82,\n",
       " 'videos': 2,\n",
       " 'from': 1095,\n",
       " 'kids': 8,\n",
       " 'loved': 8,\n",
       " \"'m\": 5,\n",
       " 'sure': 46,\n",
       " 'some': 433,\n",
       " 'them': 298,\n",
       " 'decided': 16,\n",
       " 'then': 223,\n",
       " 'there': 736,\n",
       " 'study': 28,\n",
       " 'math': 5,\n",
       " 'science': 97,\n",
       " 'eventually': 30,\n",
       " 'invested': 15,\n",
       " 'adventures': 3,\n",
       " 'company': 44,\n",
       " 'organized': 13,\n",
       " 'shuttleworth': 0,\n",
       " 'trip': 12,\n",
       " 'into': 330,\n",
       " 'soon': 48,\n",
       " 'after': 359,\n",
       " 'casually': 0,\n",
       " 'discussing': 8,\n",
       " 'notion': 6,\n",
       " 'becoming': 45,\n",
       " 'backup': 0,\n",
       " 'cosmonaut': 0,\n",
       " 'team': 34,\n",
       " 'pushing': 8,\n",
       " '2009': 40,\n",
       " 'pretty': 8,\n",
       " 'busy': 6,\n",
       " 'happened': 61,\n",
       " 'spring': 33,\n",
       " 'sister': 3,\n",
       " 'emily': 0,\n",
       " 'discovered': 18,\n",
       " 'she': 96,\n",
       " 'cancer': 38,\n",
       " 'double': 16,\n",
       " 'mastectomy': 0,\n",
       " 'doing': 58,\n",
       " 'well': 261,\n",
       " 'now': 598,\n",
       " 'fact': 142,\n",
       " 'just': 260,\n",
       " 'won': 67,\n",
       " 'mini-marathon': 0,\n",
       " 'five': 75,\n",
       " 'attacks': 25,\n",
       " 'twin': 6,\n",
       " 'towers': 3,\n",
       " 'york': 83,\n",
       " 'pentagon': 4,\n",
       " 'washington': 39,\n",
       " '9/11': 7,\n",
       " 'longer': 102,\n",
       " 'mere': 16,\n",
       " 'date': 6,\n",
       " 'most': 457,\n",
       " 'changes': 47,\n",
       " 'embodied': 3,\n",
       " 'so-called': 26,\n",
       " 'usa': 1,\n",
       " 'patriot': 3,\n",
       " 'act': 54,\n",
       " 'everyone': 76,\n",
       " 'else': 46,\n",
       " 'kind': 53,\n",
       " 'state': 238,\n",
       " 'emergency': 5,\n",
       " 'proclaimed': 6,\n",
       " 'allowed': 37,\n",
       " 'interference': 3,\n",
       " 'essential': 34,\n",
       " 'civil': 59,\n",
       " 'rights': 80,\n",
       " 'controls': 11,\n",
       " 'at': 1002,\n",
       " 'borders': 22,\n",
       " 'become': 223,\n",
       " 'ordeal': 1,\n",
       " 'many': 462,\n",
       " 'police': 31,\n",
       " 'persecution': 1,\n",
       " 'burdens': 2,\n",
       " 'quite': 33,\n",
       " 'stance': 8,\n",
       " 'prevented': 7,\n",
       " 'spread': 31,\n",
       " 'german': 84,\n",
       " 'word': 35,\n",
       " 'used': 132,\n",
       " 'other': 516,\n",
       " 'languages': 11,\n",
       " 'angst': 0,\n",
       " 'diffuse': 0,\n",
       " 'anxiety': 8,\n",
       " 'gaining': 7,\n",
       " 'ground': 31,\n",
       " 'two': 330,\n",
       " 'steps': 16,\n",
       " 'above': 65,\n",
       " 'all': 781,\n",
       " 'needed': 60,\n",
       " 'restore': 5,\n",
       " 'confidence': 31,\n",
       " 'liberty': 11,\n",
       " 'within': 108,\n",
       " 'democracies': 21,\n",
       " 'affected': 12,\n",
       " 'by': 1236,\n",
       " 'legacy': 12,\n",
       " 'eastern': 44,\n",
       " 'partnership': 19,\n",
       " 'offer': 21,\n",
       " 'any': 224,\n",
       " 'quick': 9,\n",
       " 'remedies': 0,\n",
       " 'crisis': 224,\n",
       " 'untrue': 0,\n",
       " 'problems': 116,\n",
       " 'difficulties': 10,\n",
       " 'six': 49,\n",
       " 'partners': 17,\n",
       " 'facing': 22,\n",
       " 'third': 79,\n",
       " 'way': 238,\n",
       " 'confronting': 4,\n",
       " 'russia': 278,\n",
       " 'china': 629,\n",
       " 'cold': 57,\n",
       " 'war': 326,\n",
       " 'japan': 192,\n",
       " 'remained': 27,\n",
       " 'obsessed': 5,\n",
       " 'heir': 1,\n",
       " 'soviet': 108,\n",
       " 'what': 767,\n",
       " 'we': 879,\n",
       " 'keep': 35,\n",
       " 'principles': 24,\n",
       " 'said': 99,\n",
       " 'times': 120,\n",
       " 'repetition': 2,\n",
       " 'diminish': 5,\n",
       " 'importance': 22,\n",
       " 'without': 202,\n",
       " 'ukraine': 83,\n",
       " 'manageable': 1,\n",
       " 'nation-state': 2,\n",
       " 'unmanageable': 0,\n",
       " 'empire': 44,\n",
       " 'more': 1015,\n",
       " 'decades': 66,\n",
       " 'world': 821,\n",
       " 'ii': 69,\n",
       " 'nearly': 45,\n",
       " '20': 55,\n",
       " 'particular': 54,\n",
       " 'spectacular': 6,\n",
       " 'surge': 3,\n",
       " 'uk': 36,\n",
       " 'independence': 51,\n",
       " 'party': 137,\n",
       " 'ukip': 0,\n",
       " 'only': 637,\n",
       " 'strengthen': 13,\n",
       " \"'s\": 540,\n",
       " 'long-standing': 0,\n",
       " 'latent': 0,\n",
       " 'euroskepticism': 0,\n",
       " 'figures': 15,\n",
       " 'lowest': 11,\n",
       " 'eu': 266,\n",
       " 'balanced': 8,\n",
       " 'constitution': 42,\n",
       " 'commission': 46,\n",
       " 'romano': 2,\n",
       " 'prodi': 3,\n",
       " 'proposed': 26,\n",
       " 'scheme': 12,\n",
       " 'executive': 11,\n",
       " 'right': 193,\n",
       " 'level': 66,\n",
       " 'certain': 46,\n",
       " 'services': 50,\n",
       " 'allocated': 6,\n",
       " 'broader': 9,\n",
       " 'geographic': 5,\n",
       " 'unit': 12,\n",
       " 'because': 237,\n",
       " 'externalities': 1,\n",
       " 'interdependence': 3,\n",
       " 'effects': 31,\n",
       " 'would': 582,\n",
       " 'absurd': 3,\n",
       " 'if': 519,\n",
       " 'pursued': 8,\n",
       " 'different': 200,\n",
       " 'foreign': 141,\n",
       " 'texas': 14,\n",
       " 'much': 303,\n",
       " 'true': 137,\n",
       " '2.': 0,\n",
       " 'european-level': 0,\n",
       " 'institutions': 69,\n",
       " 'guarantee': 15,\n",
       " 'functioning': 13,\n",
       " 'markets': 120,\n",
       " 'including': 67,\n",
       " 'competition': 47,\n",
       " 'commercial': 20,\n",
       " 'monetary': 58,\n",
       " 'policies': 88,\n",
       " 'activities': 19,\n",
       " 'percent': 5,\n",
       " 'total': 45,\n",
       " 'source': 41,\n",
       " 'table': 13,\n",
       " '``': 246,\n",
       " \"''\": 255,\n",
       " 'faces': 29,\n",
       " 'historic': 26,\n",
       " 'opportunity': 38,\n",
       " 'banking': 37,\n",
       " 'baby': 7,\n",
       " 'step': 36,\n",
       " 'their': 770,\n",
       " 'resistance': 13,\n",
       " 'recognizing': 5,\n",
       " 'runs': 13,\n",
       " 'deeper': 20,\n",
       " 'recently': 90,\n",
       " 'spanish': 22,\n",
       " 'authorities': 28,\n",
       " 'maintained': 2,\n",
       " 'country': 368,\n",
       " 'real-estate': 8,\n",
       " 'sector': 44,\n",
       " 'temporary': 9,\n",
       " 'case': 134,\n",
       " 'ireland': 40,\n",
       " 'situation': 74,\n",
       " 'initially': 13,\n",
       " 'reality': 57,\n",
       " 'shown': 19,\n",
       " 'approach': 67,\n",
       " 'tenable': 1,\n",
       " 'given': 75,\n",
       " 'financial': 221,\n",
       " 'integration': 41,\n",
       " 'particularly': 63,\n",
       " 'strong': 84,\n",
       " 'putting': 13,\n",
       " 'ecb': 42,\n",
       " 'charge': 25,\n",
       " 'obvious': 25,\n",
       " 'choice': 52,\n",
       " 'consider': 96,\n",
       " 'bank': 166,\n",
       " 'headquartered': 0,\n",
       " 'italy': 66,\n",
       " 'important': 182,\n",
       " 'subsidiary': 2,\n",
       " 'parent': 1,\n",
       " 'use': 135,\n",
       " 'funds': 38,\n",
       " 'reinforce': 7,\n",
       " 'liquidity': 10,\n",
       " 'officially': 4,\n",
       " 'yet': 247,\n",
       " 'acknowledged': 6,\n",
       " 'incremental': 0,\n",
       " 'worked': 42,\n",
       " 'past': 117,\n",
       " 'resulted': 11,\n",
       " 'berlin': 32,\n",
       " 'consensus': 26,\n",
       " 'change': 187,\n",
       " 'mindset': 4,\n",
       " '1987': 14,\n",
       " 'historian': 3,\n",
       " 'ray': 0,\n",
       " 'huang': 1,\n",
       " 'explained': 6,\n",
       " 'inet': 2,\n",
       " 'conference': 24,\n",
       " 'supports': 9,\n",
       " 'sacrifice': 3,\n",
       " 'interest': 91,\n",
       " 'unity': 20,\n",
       " 'myself': 10,\n",
       " 'included': 15,\n",
       " 'enlargement': 21,\n",
       " 'take': 145,\n",
       " 'among': 128,\n",
       " 'others': 130,\n",
       " 'baltic': 12,\n",
       " 'states': 311,\n",
       " 'estonia': 8,\n",
       " 'latvia': 12,\n",
       " 'lithuania': 9,\n",
       " '--': 86,\n",
       " 'republics': 4,\n",
       " 'impossible': 38,\n",
       " 'dream': 27,\n",
       " 'come': 105,\n",
       " 'comes': 64,\n",
       " 'days': 53,\n",
       " 'deal': 51,\n",
       " 'struck': 11,\n",
       " 'between': 290,\n",
       " 'tricky': 1,\n",
       " 'question': 121,\n",
       " 'access': 43,\n",
       " 'russian': 103,\n",
       " 'enclave': 3,\n",
       " 'kaliningrad': 2,\n",
       " 'piece': 6,\n",
       " '1': 48,\n",
       " 'million': 192,\n",
       " 'inhabitants': 11,\n",
       " 'bordering': 2,\n",
       " 'sea': 64,\n",
       " 'squeezed': 0,\n",
       " 'poland': 52,\n",
       " 'future': 117,\n",
       " 'members': 91,\n",
       " 'could': 378,\n",
       " 'litmus': 0,\n",
       " 'test': 37,\n",
       " 'relations': 59,\n",
       " 'regarded': 10,\n",
       " 'wild': 14,\n",
       " 'dreams': 2,\n",
       " 'fortunately': 15,\n",
       " 'multilateral': 10,\n",
       " 'option': 24,\n",
       " 'existing': 11,\n",
       " 'precedent': 8,\n",
       " 'teeth': 4,\n",
       " 'un': 84,\n",
       " 'security': 139,\n",
       " 'council': 57,\n",
       " 'indicates': 2,\n",
       " 'willing': 19,\n",
       " 'provide': 38,\n",
       " 'fuel': 16,\n",
       " 'late': 57,\n",
       " 'learn': 30,\n",
       " 'lessons': 37,\n",
       " 'misadventures': 0,\n",
       " 'a.': 1,\n",
       " 'q.': 0,\n",
       " 'khan': 1,\n",
       " 'big': 114,\n",
       " 'chance': 28,\n",
       " 'farmers': 25,\n",
       " 'vicious': 5,\n",
       " 'circle': 14,\n",
       " 'technically': 6,\n",
       " 'known': 72,\n",
       " 'poverty': 58,\n",
       " 'trap': 8,\n",
       " 'black': 42,\n",
       " 'white': 37,\n",
       " 'unusual': 16,\n",
       " 'instance': 13,\n",
       " 'pry': 1,\n",
       " 'apart': 13,\n",
       " 'your': 73,\n",
       " '[': 7,\n",
       " 'television': 33,\n",
       " ']': 7,\n",
       " 'series—check': 0,\n",
       " 'later': 75,\n",
       " '!': 57,\n",
       " 'might': 114,\n",
       " 'planning': 9,\n",
       " 'documentary': 2,\n",
       " 'racial': 6,\n",
       " 'profiling': 0,\n",
       " 'don': 72,\n",
       " 'bollywood': 4,\n",
       " 'bride': 0,\n",
       " 'sarkozy': 32,\n",
       " 'missed': 3,\n",
       " 'romantic': 5,\n",
       " 'lifetime': 6,\n",
       " 'bruni': 0,\n",
       " 'own': 206,\n",
       " 'life': 137,\n",
       " 'path': 32,\n",
       " 'closely': 19,\n",
       " 'resembles': 15,\n",
       " 'number': 97,\n",
       " 'stars': 13,\n",
       " 'who': 371,\n",
       " 'made': 149,\n",
       " 'transition': 28,\n",
       " 'model': 91,\n",
       " 'actress': 1,\n",
       " 'kissing': 0,\n",
       " 'fondling': 0,\n",
       " 'public': 171,\n",
       " 'spouses': 0,\n",
       " 'taboo': 3,\n",
       " 'respect': 37,\n",
       " 'india': 198,\n",
       " 'wants': 55,\n",
       " 'make': 200,\n",
       " 'clean': 12,\n",
       " 'break': 24,\n",
       " 'current': 94,\n",
       " 'people': 557,\n",
       " 'large': 123,\n",
       " 'part': 197,\n",
       " 'gravitas': 0,\n",
       " 'office': 39,\n",
       " 'derives': 2,\n",
       " 'pomp': 0,\n",
       " 'circumstance': 1,\n",
       " 'wedding': 2,\n",
       " 'always': 104,\n",
       " 'reception': 0,\n",
       " 'bomb': 9,\n",
       " 'every': 136,\n",
       " 'reactor': 1,\n",
       " 'ultimately': 24,\n",
       " 'doesn': 27,\n",
       " 'lie': 14,\n",
       " 'civilian': 16,\n",
       " 'nuclear': 105,\n",
       " 'energy': 103,\n",
       " 'first': 371,\n",
       " 'foremost': 10,\n",
       " 'military': 133,\n",
       " 'applications': 3,\n",
       " 'npt': 1,\n",
       " 'repeatedly': 10,\n",
       " 'violated': 2,\n",
       " 'circumvented': 0,\n",
       " 'subscribed': 0,\n",
       " 'born-again': 0,\n",
       " 'cap': 5,\n",
       " 'must': 330,\n",
       " 'born': 37,\n",
       " 'quickly': 46,\n",
       " 'came': 79,\n",
       " 'seen': 73,\n",
       " 'jewel': 1,\n",
       " 'crown': 8,\n",
       " 'project': 44,\n",
       " 'those': 234,\n",
       " '15': 45,\n",
       " '27': 12,\n",
       " 'possibilities': 7,\n",
       " 'greater': 55,\n",
       " 'development': 114,\n",
       " 'agricultural': 12,\n",
       " 'main': 52,\n",
       " 'structure': 37,\n",
       " 'compliment': 0,\n",
       " 'ecological': 4,\n",
       " 'rhetoric': 14,\n",
       " 'applied': 23,\n",
       " 'israel': 98,\n",
       " 'becomes': 24,\n",
       " 'ever': 90,\n",
       " 'extreme': 21,\n",
       " 'conducive': 1,\n",
       " 'hatred': 6,\n",
       " 'hamas': 31,\n",
       " 'mentioned': 7,\n",
       " 'either': 52,\n",
       " 'university': 58,\n",
       " 'unions': 9,\n",
       " 'motions': 0,\n",
       " 'breakthrough': 7,\n",
       " 'against': 207,\n",
       " 'hunger': 17,\n",
       " 'result': 136,\n",
       " 'grain': 9,\n",
       " 'yield': 8,\n",
       " 'example': 260,\n",
       " 'maize': 1,\n",
       " 'one-third': 13,\n",
       " 'less': 157,\n",
       " 'achieved': 33,\n",
       " 'better': 129,\n",
       " 'farm': 8,\n",
       " 'inputs': 4,\n",
       " 'african': 61,\n",
       " 'produce': 45,\n",
       " 'ton': 6,\n",
       " 'per': 89,\n",
       " 'hectare': 6,\n",
       " 'compared': 40,\n",
       " 'four': 87,\n",
       " 'tons': 5,\n",
       " 'where': 189,\n",
       " 'fertilizers': 0,\n",
       " 'heavily': 10,\n",
       " 'centers': 8,\n",
       " 'household': 12,\n",
       " 'names': 21,\n",
       " 'deserve': 9,\n",
       " 'thomas': 5,\n",
       " 'jefferson': 1,\n",
       " 'knowledge': 45,\n",
       " 'candles': 0,\n",
       " 'light': 33,\n",
       " 'another': 181,\n",
       " 'contrary': 26,\n",
       " 'everything': 58,\n",
       " 'brighter': 0,\n",
       " 'prize': 19,\n",
       " 'fund': 38,\n",
       " 'hiv/aids': 14,\n",
       " 'congressional': 2,\n",
       " 'bill': 18,\n",
       " 'introduced': 26,\n",
       " 'senator': 9,\n",
       " 'bernie': 0,\n",
       " 'sanders': 1,\n",
       " 'initiative': 33,\n",
       " 'america': 363,\n",
       " 'marks': 11,\n",
       " 'progress': 47,\n",
       " 'centerless': 0,\n",
       " 'euro': 117,\n",
       " 'hold': 31,\n",
       " 'portuguese': 5,\n",
       " 'workers': 45,\n",
       " 'fleeing': 1,\n",
       " 'booming': 0,\n",
       " 'colonies': 6,\n",
       " 'brazil': 67,\n",
       " 'macau': 0,\n",
       " 'claim': 37,\n",
       " 'hugely': 5,\n",
       " 'misguided': 5,\n",
       " 'western': 99,\n",
       " 'germans': 20,\n",
       " 'still': 207,\n",
       " 'see': 116,\n",
       " 'sight': 13,\n",
       " 'bills': 4,\n",
       " 'unification': 7,\n",
       " 'maurice': 0,\n",
       " 'obstfeld': 0,\n",
       " 'pointed': 7,\n",
       " 'out': 311,\n",
       " 'addition': 20,\n",
       " 'fiscal': 73,\n",
       " 'transfers': 11,\n",
       " 'currency': 62,\n",
       " 'clearly': 62,\n",
       " 'defined': 22,\n",
       " 'rules': 50,\n",
       " 'lender': 8,\n",
       " 'resort': 12,\n",
       " 'century': 129,\n",
       " 'chinese': 168,\n",
       " 'protests': 21,\n",
       " 'civilization': 15,\n",
       " 'very': 172,\n",
       " 'issues': 49,\n",
       " 'basis': 36,\n",
       " 'hard': 63,\n",
       " 'find': 64,\n",
       " 'clockwork': 1,\n",
       " 'chemistry': 3,\n",
       " 'remains': 128,\n",
       " 'shocking': 1,\n",
       " 'fiction': 12,\n",
       " 'aged': 4,\n",
       " 'ages': 13,\n",
       " 'fast': 26,\n",
       " 'long': 195,\n",
       " 'afterlife': 1,\n",
       " 'orange': 5,\n",
       " 'accused': 5,\n",
       " 'glorifying': 0,\n",
       " 'violence': 54,\n",
       " 'scenes': 2,\n",
       " 'watch': 11,\n",
       " 'sometimes': 43,\n",
       " 'limits': 33,\n",
       " 'rather': 94,\n",
       " 'expands': 2,\n",
       " 'our': 274,\n",
       " 'sense': 103,\n",
       " 'possible': 88,\n",
       " 'psychopathic': 0,\n",
       " 'alex': 0,\n",
       " 'help': 98,\n",
       " 'probably': 58,\n",
       " 'least': 111,\n",
       " 'hypothetical': 2,\n",
       " 'questions': 37,\n",
       " 'moral': 31,\n",
       " 'pills': 0,\n",
       " 'raise': 12,\n",
       " 'deep': 27,\n",
       " 'available': 36,\n",
       " 'say': 116,\n",
       " 'cloud': 1,\n",
       " 'over': 275,\n",
       " 'airplane': 4,\n",
       " 'safety': 20,\n",
       " 'british': 111,\n",
       " '£1.5': 0,\n",
       " 'billion': 112,\n",
       " 'similarly': 31,\n",
       " 'flower': 1,\n",
       " 'growers': 0,\n",
       " 'kenya': 15,\n",
       " 'depend': 18,\n",
       " 'air': 42,\n",
       " 'transport': 17,\n",
       " 'short-lived': 5,\n",
       " 'product': 25,\n",
       " 'suddenly': 10,\n",
       " 'income': 62,\n",
       " '3,000': 3,\n",
       " 'die': 20,\n",
       " 'roads': 12,\n",
       " 'day': 107,\n",
       " 'mill': 6,\n",
       " 'view': 75,\n",
       " 'justified': 8,\n",
       " 'stopping': 6,\n",
       " 'him': 123,\n",
       " 'he': 488,\n",
       " 'aware': 11,\n",
       " 'danger': 20,\n",
       " 'slightly': 14,\n",
       " 'crashing': 2,\n",
       " 'plane': 3,\n",
       " 'kill': 22,\n",
       " 'greatest': 31,\n",
       " 'risks': 42,\n",
       " 'far': 183,\n",
       " 'borne': 3,\n",
       " 'passengers': 3,\n",
       " 'crew': 1,\n",
       " 'communist': 53,\n",
       " 'communism': 25,\n",
       " 'according': 60,\n",
       " 'gleb': 0,\n",
       " 'pavlovsky': 0,\n",
       " 'putin': 98,\n",
       " 'regime': 67,\n",
       " 'leading': 50,\n",
       " 'ideologist': 0,\n",
       " 'system': 171,\n",
       " 'perfect': 18,\n",
       " 'respects': 5,\n",
       " 'enemies': 16,\n",
       " 'dependent': 10,\n",
       " 'gas': 41,\n",
       " 'oil': 94,\n",
       " 'before': 145,\n",
       " 'under': 169,\n",
       " 'service': 31,\n",
       " 'revenge': 1,\n",
       " 'instincts': 4,\n",
       " 'betray': 0,\n",
       " 'go': 89,\n",
       " 'back': 128,\n",
       " 'ones': 25,\n",
       " 'confederal': 0,\n",
       " 'solution': 65,\n",
       " 'palestine': 28,\n",
       " 'london': 83,\n",
       " 'month': 50,\n",
       " 'city': 103,\n",
       " 'staying': 2,\n",
       " 'hotel': 2,\n",
       " 'israeli': 28,\n",
       " 'prime': 56,\n",
       " 'minister': 87,\n",
       " 'binyamin': 0,\n",
       " 'netanyahu': 3,\n",
       " 'accommodate': 1,\n",
       " 'converted': 5,\n",
       " 'fortress': 1,\n",
       " 'negotiated': 6,\n",
       " 'land': 50,\n",
       " 'peace': 123,\n",
       " 'official': 44,\n",
       " 'doctrine': 6,\n",
       " 'jews': 23,\n",
       " 'bound': 13,\n",
       " 'stay': 16,\n",
       " 'jerusalem': 13,\n",
       " 'arabs': 11,\n",
       " 'proper': 9,\n",
       " 'mean': 80,\n",
       " 'work': 163,\n",
       " 'time': 332,\n",
       " 'confederation': 4,\n",
       " 'kosovo': 33,\n",
       " 'running': 27,\n",
       " 'serbia': 31,\n",
       " 'claims': 18,\n",
       " 'province': 44,\n",
       " 'historical': 39,\n",
       " 'tradition': 19,\n",
       " 'thus': 90,\n",
       " 'gain': 22,\n",
       " 'trappings': 1,\n",
       " 'statehood': 2,\n",
       " 'major': 100,\n",
       " 'themes': 3,\n",
       " 'citizens': 63,\n",
       " 'believe': 73,\n",
       " 'rightly': 10,\n",
       " 'mass': 33,\n",
       " 'media': 42,\n",
       " 'failing': 6,\n",
       " 'investigate': 3,\n",
       " 'document': 11,\n",
       " 'abuses': 9,\n",
       " 'hence': 16,\n",
       " 'impulse': 1,\n",
       " 'unseen': 2,\n",
       " 'forces': 75,\n",
       " 'sopuissant': 0,\n",
       " 'caesar': 0,\n",
       " 'reproach': 1,\n",
       " ...}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_count = sum(unigram_counts.values())\n",
    "\n",
    "def check_for_unk_test(word,unigram_counts):\n",
    "    if word in unigram_counts and unigram_counts[word] > 0:\n",
    "        return word\n",
    "    else:\n",
    "        return \"UNK\"\n",
    "\n",
    "def convert_sentence_test(sentence,unigram_counts):\n",
    "    return [\"<s1>\"] + [\"<s2>\"] + [check_for_unk_test(word.lower(),unigram_counts) for word in sentence] + [\"</s2>\"]  + [\"</s1>\"]\n",
    "\n",
    "def get_log_prob_addk(word,unigram_counts,k):\n",
    "    return math.log((unigram_counts[word] + k)/(token_count + k*len(unigram_counts)))\n",
    "\n",
    "def get_sent_log_prob_addk(sentence, unigram_counts,k):\n",
    "    sentence = convert_sentence_test(sentence, unigram_counts)\n",
    "    return sum([get_log_prob_addk(word, unigram_counts,k) for word in sentence])\n",
    "\n",
    "def calculate_perplexity_uni(sentences,unigram_counts, token_count, k):\n",
    "    total_log_prob = 0\n",
    "    test_token_count = 0\n",
    "    for sentence in sentences:\n",
    "        test_token_count += len(sentence) + 2\n",
    "        total_log_prob += get_sent_log_prob_addk(sentence,unigram_counts,k)\n",
    "    return math.exp(-total_log_prob/test_token_count)\n",
    "\n",
    "f = open(NEWSTEST_ENG)\n",
    "\n",
    "test_sents = []\n",
    "for line in f:\n",
    "    test_sents.append(tokenize(line))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001: 631.5624344258267\n",
      "0.01: 631.6372709016225\n",
      "0.1: 632.3728621611093\n",
      "1: 643.2578962510463\n",
      "10: 814.7925245672897\n"
     ]
    }
   ],
   "source": [
    "ks = [0.0001,0.01,0.1,1,10]\n",
    "for k in ks:\n",
    "    print(str(k) +\": \" + str(calculate_perplexity_uni(test_sents,unigram_counts,token_count,k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate import IBMModel1\n",
    "from nltk.translate import AlignedSent\n",
    "\n",
    "eng_sents = []\n",
    "de_sents = []\n",
    "\n",
    "f = open(BITEXT_ENG)\n",
    "for line in f:\n",
    "    terms = tokenize(line)\n",
    "    eng_sents.append(terms)\n",
    "f.close()\n",
    "\n",
    "f = open(BITEXT_DE)\n",
    "for line in f:\n",
    "    terms = tokenize(line)\n",
    "    de_sents.append(terms)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "paral_sents = list(zip(eng_sents,de_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_de_bt = [AlignedSent(E,G) for E,G in paral_sents]\n",
    "eng_de_m = IBMModel1(eng_de_bt, 5)\n",
    "\n",
    "de_eng_bt = [AlignedSent(G,E) for E,G in paral_sents]\n",
    "de_eng_m = IBMModel1(de_eng_bt, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_align = []\n",
    "for i in range(len(eng_de_bt)):\n",
    "    forward = {x for x in eng_de_bt[i].alignment}\n",
    "    back_reversed = {x[::-1] for x in de_eng_bt[i].alignment}\n",
    "    combined_align.append(forward.intersection(back_reversed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_eng_count = defaultdict(dict)\n",
    "for i in range(len(de_eng_bt)):\n",
    "    for item in combined_align[i]:\n",
    "        de_eng_count[de_eng_bt[i].words[item[1]]][de_eng_bt[i].mots[item[0]]] =  de_eng_count[de_eng_bt[i].words[item[1]]].get(de_eng_bt[i].mots[item[0]],0) + 1\n",
    "\n",
    "eng_de_count = defaultdict(dict)\n",
    "for i in range(len(eng_de_bt)):\n",
    "    for item in combined_align[i]:\n",
    "        eng_de_count[eng_de_bt[i].words[item[0]]][eng_de_bt[i].mots[item[1]]] =  eng_de_count[eng_de_bt[i].words[item[0]]].get(eng_de_bt[i].mots[item[1]],0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_eng_prob = defaultdict(dict)\n",
    "for de in de_eng_count.keys():\n",
    "    for eng in de_eng_count[de].keys():\n",
    "        de_eng_prob[de][eng] = de_eng_count[de][eng]/sum(de_eng_count[de].values())\n",
    "\n",
    "\n",
    "eng_de_prob = defaultdict(dict)\n",
    "for eng in eng_de_count.keys():\n",
    "    for de in eng_de_count[eng].keys():\n",
    "        eng_de_prob[eng][de] = eng_de_count[eng][de]/sum(eng_de_count[eng].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 1.0}\n",
      "{'spans': 0.5, 'side': 0.5}\n",
      "{'house': 0.625, 'charity': 0.125, 'hospitalized': 0.125, 'offset': 0.125}\n",
      "{'the': 1.0}\n",
      "{'english': 0.875, 'significantly': 0.125}\n"
     ]
    }
   ],
   "source": [
    "print(de_eng_prob['frage'])\n",
    "print(de_eng_prob['handlung'])\n",
    "print(de_eng_prob['haus'])\n",
    "print(de_eng_prob['die'])\n",
    "print(de_eng_prob['englisch'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_eng_noisy(german):\n",
    "    noisy={}\n",
    "    for eng in de_eng_prob[german].keys():\n",
    "        noisy[eng] = eng_de_prob[eng][german]+ get_log_prob_addk(eng,unigram_counts,0.0001)\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'irische': 0.25, 'glücklich': 0.25, 'portemonnaie': 0.25, 'vorläufig': 0.25}\n",
      "{'den': 0.030258662762323085, 'die': 0.7484952009110135, 'der': 0.2010736944851147, 'das': 0.014803969415975272, 'des': 0.002277533756303888, 'dem': 0.0016268098259313486, 'im': 0.0014641288433382138}\n",
      "{'traurigen': 0.5, 'vielzahl': 0.5}\n",
      "{'englisch': 0.7777777777777778, 'englische': 0.1111111111111111, 'megalomanischen': 0.1111111111111111}\n",
      "{'haus': 0.8333333333333334, 'ade': 0.16666666666666666}\n"
     ]
    }
   ],
   "source": [
    "print(eng_de_prob['happy'])\n",
    "print(eng_de_prob['the'])\n",
    "print(eng_de_prob['sad'])\n",
    "print(eng_de_prob['english'])\n",
    "print(eng_de_prob['house'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 1.0}\n",
      "{'spans': 0.5, 'side': 0.5}\n",
      "{'house': 0.625, 'charity': 0.125, 'hospitalized': 0.125, 'offset': 0.125}\n",
      "{'the': 1.0}\n",
      "{'english': 0.875, 'significantly': 0.125}\n"
     ]
    }
   ],
   "source": [
    "print(de_eng_prob['frage'])\n",
    "print(de_eng_prob['handlung'])\n",
    "print(de_eng_prob['haus'])\n",
    "print(de_eng_prob['die'])\n",
    "print(de_eng_prob['englisch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "German: der ( von engl . action : tat , handlung , bewegung ) ist ein filmgenre des unterhaltungskinos , in welchem der fortgang der äußeren handlung von zumeist spektakulär inszenierten kampf - und gewaltszenen vorangetrieben und illustriert wird .\n",
      "\n",
      "English: the ( , leninism . action : rattling , side , movement ) is a filmgenre the unterhaltungskinos , in paulson the fortgang the trumpet side , zumeist spektakulär inszenierten fight - and gewaltszenen annan and illustriert is .\n",
      "\n",
      "\n",
      "116\n",
      "German: die ( einheitenzeichen : u für unified atomic mass unit , veraltet amu für atomic mass unit ) ist eine maßeinheit der masse .\n",
      "\n",
      "English: the ( einheitenzeichen : u for unified atomic manipulation unit , regime amu for atomic manipulation unit ) is a befuddled the masse .\n",
      "\n",
      "\n",
      "240\n",
      "German: der von lateinisch actualis , \" wirklich \" , auch aktualitätsprinzip , uniformitäts - oder gleichförmigkeitsprinzip , englisch uniformitarianism , ist die grundlegende wissenschaftliche methode in der .\n",
      "\n",
      "English: the , lateinisch actualis , `` really `` , not aktualitätsprinzip , uniformitäts - or gleichförmigkeitsprinzip , english uniformitarianism , is the basic intended method in the .\n",
      "\n",
      "\n",
      "320\n",
      "German: die ( griechisch el , von altgriechisch grc , - \" zusammen - \" , \" anbinden \" , gemeint ist \" die herzbeutel angehängte \" ) , ist ein blutgefäß , welches das blut vom herz wegführt .\n",
      "\n",
      "English: the ( griechisch el , , altgriechisch grc , - `` zusammen - `` , `` anbinden `` , meant is `` the herzbeutel angehängte `` ) , is a blutgefäß , welches the blood vom herz wegführt .\n",
      "\n",
      "\n",
      "540\n",
      "German: unter der bezeichnung fasst man die drei im nördlichen alpenvorland liegenden gewässereinheiten obersee , untersee und seerhein zusammen .\n",
      "\n",
      "English: under the eurasian fasst man the three the nördlichen alpenvorland underlying gewässereinheiten obersee , untersee and seerhein zusammen .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def de_eng_direct(query):\n",
    "    query_english = [] \n",
    "    query_tokens = tokenize(query)\n",
    "    \n",
    "    for token in query_tokens:\n",
    "        try:\n",
    "            query_english.append(max(de_eng_prob[token], key=de_eng_prob[token].get))\n",
    "        except:\n",
    "            query_english.append(token)\n",
    "    return \" \".join(query_english)\n",
    "\n",
    "def de_eng_noisy_translate(query):  \n",
    "    query_english = [] \n",
    "    query_tokens = tokenize(query)\n",
    "    for token in query_tokens:\n",
    "        try:\n",
    "            query_english.append(max(de_eng_noisy(token), key=de_eng_noisy(token).get))\n",
    "        except:\n",
    "            query_english.append(token)\n",
    "    return \" \".join(query_english)\n",
    "f = open(DEVELOPMENT_QUERIES)\n",
    "lno = plno = 0\n",
    "german_qs, test_query_trans_sents = {}, []\n",
    "for line in f:\n",
    "    lno+=1\n",
    "    query_id = line.split('\\t')[0]\n",
    "    query_german = line.split('\\t')[1]  \n",
    "    german_qs[query_id] = query_german.strip()\n",
    "    translation = str(de_eng_noisy_translate(query_german))\n",
    "    if plno<5:\n",
    "        print(query_id + \"\\n\" + \"German: \" + str(query_german) + \"\\n\" + \"English: \" + translation +\"\\n\\n\")\n",
    "        plno+=1\n",
    "    test_query_trans_sents.append(translation)\n",
    "    if lno==100:\n",
    "        break\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
